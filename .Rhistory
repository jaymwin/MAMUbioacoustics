token = token
)
# view data
glimpse(epi_df)
# define the paths for input and output
# these will need to be adjusted for your machine
input_dir <- "C:/Users/jmwin/OneDrive/Desktop/test_SD_card" # SD card directory
temp_dir <- "C:/Users/jmwin/OneDrive/Desktop/temp" # temporary folder, can be anywhere locally
output_dir <- "E:/2025/flacs" # external hard drive
# Set up parallel processing using furrr
plan(multisession, workers = availableCores() - 1)  # Use all but 1 core for processing
tictoc::tic()
copy_compress_flacs(
# deployment info
deployment_df = epi_df,
# SD card location
input_dir = input_dir,
# location to temporarily (and locally) store wavs
temp_dir = temp_dir,
# external hard drive location
output_dir = output_dir
)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
deployment_df <- epi_df
# define the paths for input and output
# these will need to be adjusted for your machine
input_dir <- "C:/Users/jmwin/OneDrive/Desktop/test_SD_card" # SD card directory
temp_dir <- "C:/Users/jmwin/OneDrive/Desktop/temp" # temporary folder, can be anywhere locally
output_dir <- "E:/2025/flacs" # external hard drive
# Set up parallel processing using furrr
plan(multisession, workers = availableCores() - 1)  # Use all but 1 core for processing
# List all .wav files in the input directory
wav_files <- list.files(input_dir, pattern = "\\.wav$", full.names = TRUE, recursive = TRUE)
# create pond/swift/date folders if necessary
# name output files based on wav files
swift <- stringr::str_extract(wav_files[1], 'S[0-9]+')
site <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::distinct(site_name) |>
dplyr::pull(site_name)
cell <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::distinct(cell_id) |>
dplyr::pull(cell_id)
station <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::distinct(mamu_station_id) |>
dplyr::pull(mamu_station_id)
visit <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::filter(visit_id == max(visit_id)) |>
dplyr::pull(visit_id) %>%
stringr::str_c('V', .)
message(stringr::str_glue('site name = {site}, visit ID = {visit}, cell ID = {cell}, MAMU station ID = {station}'))
wav_files |>
purrr::walk(\(x) create_temp_folders(wav_file = x, input_dir = input_dir, temp_dir = temp_dir))
# create flac folders on an external hard drive
create_flac_folders <- function(date, output_dir, site_name, visit_id, cell_id, station_id) {
fs::dir_create(
path = stringr::str_glue('{output_dir}/{site_name}_{visit_id}/{site_name}_{visit_id}_{cell_id}_{station_id}/{site_name}_{visit_id}_{cell_id}_{station_id}_{date}')
)
}
# create flac folders on an external hard drive
create_flac_folders <- function(date, output_dir, site_name, visit_id, cell_id, station_id) {
fs::dir_create(
path = stringr::str_glue('{output_dir}/{site_name}_{visit_id}/{site_name}_{visit_id}_{cell_id}_{station_id}/{site_name}_{visit_id}_{cell_id}_{station_id}_{date}')
)
}
dates <- unique(stringr::str_extract(wav_files, '[0-9]{8}'))
dates
dates <- unique(stringr::str_extract(wav_files, '[0-9]{8}'))
dates |>
purrr::walk(\(x) create_flac_folders(date = x, output_dir = output_dir, site_name = site, visit_id = visit, cell_id = cell, station_id = station))
dates <- unique(stringr::str_extract(wav_files, '[0-9]{8}'))
output_dir
site
visit
cell
station
dates |>
purrr::walk(\(x) create_flac_folders(date = x, output_dir = output_dir, site_name = site, visit_id = visit, cell_id = cell, station_id = station))
wav_files |>
furrr::future_walk(\(x) convert_to_flac(wav_file = x, input_dir = input_dir, temp_dir = temp_dir, output_dir = output_dir, site_name = site, visit_id = visit, cell_id = cell, station_id = station, swift_id = swift))
convert_to_flac
wav_files |>
furrr::future_walk(\(x) MAMUbioacoustics:::convert_to_flac(wav_file = x, input_dir = input_dir, temp_dir = temp_dir, output_dir = output_dir, site_name = site, visit_id = visit, cell_id = cell, station_id = station, swift_id = swift))
temp_path <-
stringr::str_c(stringr::str_replace(stringr::str_remove(stringr::str_replace(wav_file, "\\(-\\d{4}\\)", ""), basename(stringr::str_replace(wav_file, "\\(-\\d{4}\\)", ""))), input_dir, temp_dir), basename(stringr::str_replace(wav_file, "\\(-\\d{4}\\)", "")))
wav_file <- wav_files[1]
temp_path <-
stringr::str_c(stringr::str_replace(stringr::str_remove(stringr::str_replace(wav_file, "\\(-\\d{4}\\)", ""), basename(stringr::str_replace(wav_file, "\\(-\\d{4}\\)", ""))), input_dir, temp_dir), basename(stringr::str_replace(wav_file, "\\(-\\d{4}\\)", "")))
temp_path
fs::file_copy(
path = wav_file,
new_path = temp_path,
overwrite = FALSE
)
date <- stringr::str_extract(wav_file, '[0-9]{8}')
date
# Define the output flac file path
output_file <-
file.path(
stringr::str_glue(
'{output_dir}/{site_name}_{visit_id}/{site_name}_{visit_id}_{cell_id}_{station_id}/{site_name}_{visit_id}_{cell_id}_{station_id}_{date}/{site_name}_{visit_id}_{cell_id}_{station_id}{stringr::str_replace(stringr::str_remove(basename(temp_path), swift_id), "wav", "flac")}'
)
)
site_name <- site
# Define the output flac file path
output_file <-
file.path(
stringr::str_glue(
'{output_dir}/{site_name}_{visit_id}/{site_name}_{visit_id}_{cell_id}_{station_id}/{site_name}_{visit_id}_{cell_id}_{station_id}_{date}/{site_name}_{visit_id}_{cell_id}_{station_id}{stringr::str_replace(stringr::str_remove(basename(temp_path), swift_id), "wav", "flac")}'
)
)
visit_id <- visit
# Define the output flac file path
output_file <-
file.path(
stringr::str_glue(
'{output_dir}/{site_name}_{visit_id}/{site_name}_{visit_id}_{cell_id}_{station_id}/{site_name}_{visit_id}_{cell_id}_{station_id}_{date}/{site_name}_{visit_id}_{cell_id}_{station_id}{stringr::str_replace(stringr::str_remove(basename(temp_path), swift_id), "wav", "flac")}'
)
)
cell_id <- cell
# Define the output flac file path
output_file <-
file.path(
stringr::str_glue(
'{output_dir}/{site_name}_{visit_id}/{site_name}_{visit_id}_{cell_id}_{station_id}/{site_name}_{visit_id}_{cell_id}_{station_id}_{date}/{site_name}_{visit_id}_{cell_id}_{station_id}{stringr::str_replace(stringr::str_remove(basename(temp_path), swift_id), "wav", "flac")}'
)
)
station_id <- station
# Define the output flac file path
output_file <-
file.path(
stringr::str_glue(
'{output_dir}/{site_name}_{visit_id}/{site_name}_{visit_id}_{cell_id}_{station_id}/{site_name}_{visit_id}_{cell_id}_{station_id}_{date}/{site_name}_{visit_id}_{cell_id}_{station_id}{stringr::str_replace(stringr::str_remove(basename(temp_path), swift_id), "wav", "flac")}'
)
)
swift_id <- swift
# Define the output flac file path
output_file <-
file.path(
stringr::str_glue(
'{output_dir}/{site_name}_{visit_id}/{site_name}_{visit_id}_{cell_id}_{station_id}/{site_name}_{visit_id}_{cell_id}_{station_id}_{date}/{site_name}_{visit_id}_{cell_id}_{station_id}{stringr::str_replace(stringr::str_remove(basename(temp_path), swift_id), "wav", "flac")}'
)
)
output_file
# Use sox to convert the wav file to flac
# The '-C 8' option sets compression level for FLAC (range 0-8, where 8 is the highest compression)
seewave::sox(
stringr::str_glue('"{temp_path}" "{output_file}"'),
path2exe = "C:/Program Files (x86)/sox-14-4-2"
)
file.exists(output_file)
flac_files <- list.files(stringr::str_glue('{output_dir}/{site}_{visit}/{site}_{visit}_{cell}_{station}'), pattern = "\\.flac$", full.names = FALSE, recursive = TRUE)
flac_files
print(length(flac_files))
stopifnot('Number of WAV files does not match number of FLAC files compressed' = length(wav_files) == length(flac_files))
wav_files
library(devtools)
load_all()
?map_deployments
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
map_deployments(epi_df)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
map_deployments(epi_df)
map_deployments
load_all()
library(tidyverse)
library(furrr)
# read in deployment data from epicollect ---------------------------------
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
map_deployments(epi_df)
m <- map_deployments(epi_df)
mapview::mapshot(m, url = here::here('mamu_deployment_map.html'))
mapview::mapshot(m, url = here::here('C:/Users/jmwin/OneDrive/Desktop/mamu_deployment_map.html'))
library(devtools)
load_all()
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
m <- map_deployments(epi_df)
mapview::mapshot(m, url = here::here('C:/Users/jmwin/OneDrive/Desktop/mamu_deployment_map.html'))
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
library(devtools)
load_all()
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
m <- map_deployments(epi_df)
mapview::mapshot(m, url = here::here('C:/Users/jmwin/OneDrive/Desktop/mamu_deployment_map.html'))
epi_df
epi_df
library(readxl)
site_station_codes_df <-
read_excel(here::here('data-raw/site_station_codes.xlsx'))
site_station_codes_df
site_station_codes <-
readxl::read_excel(here::here('data-raw/site_station_codes.xlsx'))
# this updates the /data folder
usethis::use_data(site_station_codes, overwrite = TRUE)
load_all()
site_station_codes
epi_df
site_station_codes
epi_df
epi_df |>
slice(3)
epi_df |>
slice(3) |>
glimpse()
site_station_codes |>
select(location_type:code)
epi_df |>
slice(3) |>
glimpse()
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code)
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code) |>
drop_na()
site_station_codes |>
filter(location_type == 'site') |>
select(organization, site_name = full_name, site_code = code) |>
drop_na()
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code) |>
drop_na()
site_codes <-
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code) |>
drop_na()
station_codes <-
site_station_codes |>
filter(location_type == 'station') |>
select(mamu_station_id = full_name, station_code = code) |>
drop_na()
station_codes
read_epicollect <- function(project_slug, token) {
# create url to access data
# I removed form.ref from this string to get this working
url_form <-
paste(
"https://five.epicollect.net/api/export/entries/",
project_slug,
"?map_index=0&form_ref=",
# had to add per_page limit because it was only reading 50 records at a time
"&format=csv&headers=true&per_page=1000",
sep = ""
)
# get URL
res1 <-
httr::GET(
url_form,
httr::add_headers("Authorization" = paste("Bearer", token))
)
# check it worked to access
message(httr::http_status(res1)$message)
# read in csv of deployment/retrieval data
df <-
readr::read_csv(
res1$url
) |>
dplyr::select(5:24, 29) |>
dplyr::rename(
deploy_or_retrieval = dplyr::matches('Deployment_or'),
deployer_name = dplyr::matches('Your_name'),
deployer_org = dplyr::matches('Your_organization'),
uw_site_name = dplyr::matches('UW_site_name'),
cell_id = dplyr::matches('UW_cell'),
uw_mamu_station_id = dplyr::matches('UW_MAMU_station_ID'),
ncasi_site_name = dplyr::matches('NCASI_site_name'),
ncasi_mamu_station_id = dplyr::matches('NCASI_MAMU_station'),
cal_fire_site_name = dplyr::matches('CAL_FIRE_site_name'),
cal_fire_mamu_station_id = dplyr::matches('CAL_FIRE_MAMU_sta'),
swift_id = dplyr::matches('Swift_ID'),
deployed_sd_card_id = dplyr::matches('Deployed_SD_card'),
retrieved_sd_card_id = dplyr::matches('Retrieved_SD_card'),
aru_status = dplyr::matches('ARU_light'),
date = dplyr::matches('Date'),
time = dplyr::matches('Time'),
aru_photo_url = dplyr::matches('Picture_of_deploy'),
lat = dplyr::matches('lat_'),
long = dplyr::matches('long_'),
comments = dplyr::matches('Comments')
) |>
dplyr::mutate(
site_name = dplyr::coalesce(uw_site_name, ncasi_site_name, cal_fire_site_name),
mamu_station_id = dplyr::coalesce(uw_mamu_station_id, ncasi_mamu_station_id, cal_fire_mamu_station_id),
date = lubridate::dmy(date)#,
# mamu_station_id = gsub("[- ]", "_", tolower(mamu_station_id))
) |>
dplyr::group_by(swift_id) |>
dplyr::mutate(visit_id = dplyr::row_number() - 1) |>
dplyr::ungroup() |>
dplyr::select(deploy_or_retrieval:deployer_org, site_name, visit_id, cell_id, mamu_station_id, swift_id:comments)
}
load_all()
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
epi_df |>
slice(3) |>
glimpse()
site_codes <-
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code) |>
drop_na()
station_codes <-
site_station_codes |>
filter(location_type == 'station') |>
select(mamu_station_id = full_name, station_code = code) |>
drop_na()
site_codes
station_codes
station_codes
station_codes |>
print(n = Inf)
station_codes |>
slice(22)
# Load necessary package
library(dplyr)
# Example data frames
df <- tibble(
mamu_station_id = c('H-M12 03A', 'H-M12 04B', 'H-M12 05C'),
other_column = c(1, 2, 3)
)
df
station_codes_df <- tibble(
mamu_station_id = c('H-M12 03A'),
station_code = c('AV022')
)
# Perform the left join and replace the mamu_station_id
df_updated <- df %>%
left_join(station_codes_df, by = "mamu_station_id") %>%
mutate(mamu_station_id = coalesce(station_code, mamu_station_id)) %>%
select(-station_code)
df_updated
?drop_na
# site/station codes from full names --------------------------------------
site_station_codes <-
readxl::read_excel(here::here('data-raw/site_station_codes.xlsx'))
site_codes <-
site_station_codes |>
dplyr::filter(location_type == 'site') |>
dplyr::select(site_name = full_name, site_code = code) |>
tidyr::drop_na()
station_codes <-
site_station_codes |>
dplyr::filter(location_type == 'station') |>
dplyr::select(mamu_station_id = full_name, station_code = code) |>
tidyr::drop_na()
# this updates the /data folder
usethis::use_data(site_codes, overwrite = TRUE)
usethis::use_data(station_codes, overwrite = TRUE)
load_all()
MAMUbioacoustics::site_codes
library(devtools)
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
load_all()
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
epi_df
# view data
glimpse(epi_df)
library(devtools)
load_all()
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
library(devtools)
