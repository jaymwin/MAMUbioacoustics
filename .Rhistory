mapview::mapshot(m, url = here::here('C:/Users/jmwin/OneDrive/Desktop/mamu_deployment_map.html'))
epi_df
epi_df
library(readxl)
site_station_codes_df <-
read_excel(here::here('data-raw/site_station_codes.xlsx'))
site_station_codes_df
site_station_codes <-
readxl::read_excel(here::here('data-raw/site_station_codes.xlsx'))
# this updates the /data folder
usethis::use_data(site_station_codes, overwrite = TRUE)
load_all()
site_station_codes
epi_df
site_station_codes
epi_df
epi_df |>
slice(3)
epi_df |>
slice(3) |>
glimpse()
site_station_codes |>
select(location_type:code)
epi_df |>
slice(3) |>
glimpse()
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code)
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code) |>
drop_na()
site_station_codes |>
filter(location_type == 'site') |>
select(organization, site_name = full_name, site_code = code) |>
drop_na()
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code) |>
drop_na()
site_codes <-
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code) |>
drop_na()
station_codes <-
site_station_codes |>
filter(location_type == 'station') |>
select(mamu_station_id = full_name, station_code = code) |>
drop_na()
station_codes
read_epicollect <- function(project_slug, token) {
# create url to access data
# I removed form.ref from this string to get this working
url_form <-
paste(
"https://five.epicollect.net/api/export/entries/",
project_slug,
"?map_index=0&form_ref=",
# had to add per_page limit because it was only reading 50 records at a time
"&format=csv&headers=true&per_page=1000",
sep = ""
)
# get URL
res1 <-
httr::GET(
url_form,
httr::add_headers("Authorization" = paste("Bearer", token))
)
# check it worked to access
message(httr::http_status(res1)$message)
# read in csv of deployment/retrieval data
df <-
readr::read_csv(
res1$url
) |>
dplyr::select(5:24, 29) |>
dplyr::rename(
deploy_or_retrieval = dplyr::matches('Deployment_or'),
deployer_name = dplyr::matches('Your_name'),
deployer_org = dplyr::matches('Your_organization'),
uw_site_name = dplyr::matches('UW_site_name'),
cell_id = dplyr::matches('UW_cell'),
uw_mamu_station_id = dplyr::matches('UW_MAMU_station_ID'),
ncasi_site_name = dplyr::matches('NCASI_site_name'),
ncasi_mamu_station_id = dplyr::matches('NCASI_MAMU_station'),
cal_fire_site_name = dplyr::matches('CAL_FIRE_site_name'),
cal_fire_mamu_station_id = dplyr::matches('CAL_FIRE_MAMU_sta'),
swift_id = dplyr::matches('Swift_ID'),
deployed_sd_card_id = dplyr::matches('Deployed_SD_card'),
retrieved_sd_card_id = dplyr::matches('Retrieved_SD_card'),
aru_status = dplyr::matches('ARU_light'),
date = dplyr::matches('Date'),
time = dplyr::matches('Time'),
aru_photo_url = dplyr::matches('Picture_of_deploy'),
lat = dplyr::matches('lat_'),
long = dplyr::matches('long_'),
comments = dplyr::matches('Comments')
) |>
dplyr::mutate(
site_name = dplyr::coalesce(uw_site_name, ncasi_site_name, cal_fire_site_name),
mamu_station_id = dplyr::coalesce(uw_mamu_station_id, ncasi_mamu_station_id, cal_fire_mamu_station_id),
date = lubridate::dmy(date)#,
# mamu_station_id = gsub("[- ]", "_", tolower(mamu_station_id))
) |>
dplyr::group_by(swift_id) |>
dplyr::mutate(visit_id = dplyr::row_number() - 1) |>
dplyr::ungroup() |>
dplyr::select(deploy_or_retrieval:deployer_org, site_name, visit_id, cell_id, mamu_station_id, swift_id:comments)
}
load_all()
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
epi_df |>
slice(3) |>
glimpse()
site_codes <-
site_station_codes |>
filter(location_type == 'site') |>
select(site_name = full_name, site_code = code) |>
drop_na()
station_codes <-
site_station_codes |>
filter(location_type == 'station') |>
select(mamu_station_id = full_name, station_code = code) |>
drop_na()
site_codes
station_codes
station_codes
station_codes |>
print(n = Inf)
station_codes |>
slice(22)
# Load necessary package
library(dplyr)
# Example data frames
df <- tibble(
mamu_station_id = c('H-M12 03A', 'H-M12 04B', 'H-M12 05C'),
other_column = c(1, 2, 3)
)
df
station_codes_df <- tibble(
mamu_station_id = c('H-M12 03A'),
station_code = c('AV022')
)
# Perform the left join and replace the mamu_station_id
df_updated <- df %>%
left_join(station_codes_df, by = "mamu_station_id") %>%
mutate(mamu_station_id = coalesce(station_code, mamu_station_id)) %>%
select(-station_code)
df_updated
?drop_na
# site/station codes from full names --------------------------------------
site_station_codes <-
readxl::read_excel(here::here('data-raw/site_station_codes.xlsx'))
site_codes <-
site_station_codes |>
dplyr::filter(location_type == 'site') |>
dplyr::select(site_name = full_name, site_code = code) |>
tidyr::drop_na()
station_codes <-
site_station_codes |>
dplyr::filter(location_type == 'station') |>
dplyr::select(mamu_station_id = full_name, station_code = code) |>
tidyr::drop_na()
# this updates the /data folder
usethis::use_data(site_codes, overwrite = TRUE)
usethis::use_data(station_codes, overwrite = TRUE)
load_all()
MAMUbioacoustics::site_codes
library(devtools)
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
load_all()
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
epi_df
# view data
glimpse(epi_df)
library(devtools)
load_all()
library(tidyverse)
library(furrr)
# get token to access EpiCollect data
token <-
get_access_token(
client_id = '5971',
client_secret = 'ROp47DpAnDaQATMWWYOB26fHyu4xPOmvkfMXWtfF'
)
# read in data from EpiCollect
epi_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = token
)
# view data
glimpse(epi_df)
library(devtools)
library(devtools)
use_r('shiny_wav_to_flac')
sd_card_path <- 'E:/'
# wav count
n_wavs <- length(fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav'))
n_wavs
# recording dates
min_date <-
fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav') |>
stringr::str_extract('[0-9]{8}') |>
lubridate::ymd() |>
min()
max_date <-
fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav') |>
stringr::str_extract('[0-9]{8}') |>
lubridate::ymd() |>
max()
min_date
max_date
# deployment_name
swift <-
fs::dir_ls(sd_card_path) |>
stringr::str_subset('S[0-9]{4}') |>
head(1) |>
stringr::str_extract('S[0-9]{4}')
swift
deployment_df <-
MAMUbioacoustics::read_epicollect(
project_slug = 'mamu-arus',
token = '1fc5154632994f179f7d8b17214e26cb'
)
deployment_df
_
_
sd_card_path <- 'E:/'
# wav count
n_wavs <- length(fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav'))
# recording dates
min_date <-
fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav') |>
stringr::str_extract('[0-9]{8}') |>
lubridate::ymd() |>
min()
max_date <-
fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav') |>
stringr::str_extract('[0-9]{8}') |>
lubridate::ymd() |>
max()
# deployment_name
swift <-
fs::dir_ls(sd_card_path) |>
stringr::str_subset('S[0-9]{4}') |>
head(1) |>
stringr::str_extract('S[0-9]{4}')
deployment_df
site <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::distinct(site_code) |>
dplyr::pull(site_code)
read_epicollect <- function(project_slug, token) {
# create url to access data
# I removed form.ref from this string to get this working
url_form <-
paste(
"https://five.epicollect.net/api/export/entries/",
project_slug,
"?map_index=0&form_ref=",
# had to add per_page limit because it was only reading 50 records at a time
"&format=csv&headers=true&per_page=1000",
sep = ""
)
# get URL
res1 <-
httr::GET(
url_form,
httr::add_headers("Authorization" = paste("Bearer", token))
)
# check it worked to access
message(httr::http_status(res1)$message)
# read in csv of deployment/retrieval data
df <-
readr::read_csv(
res1$url
) |>
dplyr::select(5:24, 29) |>
dplyr::rename(
deploy_or_retrieval = dplyr::matches('Deployment_or'),
deployer_name = dplyr::matches('Your_name'),
deployer_org = dplyr::matches('Your_organization'),
uw_site_name = dplyr::matches('UW_site_name'),
cell_id = dplyr::matches('UW_cell'),
uw_mamu_station_id = dplyr::matches('UW_MAMU_station_ID'),
ncasi_site_name = dplyr::matches('NCASI_site_name'),
ncasi_mamu_station_id = dplyr::matches('NCASI_MAMU_station'),
cal_fire_site_name = dplyr::matches('CAL_FIRE_site_name'),
cal_fire_mamu_station_id = dplyr::matches('CAL_FIRE_MAMU_sta'),
swift_id = dplyr::matches('Swift_ID'),
deployed_sd_card_id = dplyr::matches('Deployed_SD_card'),
retrieved_sd_card_id = dplyr::matches('Retrieved_SD_card'),
aru_status = dplyr::matches('ARU_light'),
date = dplyr::matches('Date'),
time = dplyr::matches('Time'),
aru_photo_url = dplyr::matches('Picture_of_deploy'),
lat = dplyr::matches('lat_'),
long = dplyr::matches('long_'),
comments = dplyr::matches('Comments')
) |>
dplyr::mutate(
site_name = dplyr::coalesce(uw_site_name, ncasi_site_name, cal_fire_site_name),
mamu_station_id = dplyr::coalesce(uw_mamu_station_id, ncasi_mamu_station_id, cal_fire_mamu_station_id),
date = lubridate::dmy(date)#,
# mamu_station_id = gsub("[- ]", "_", tolower(mamu_station_id))
) |>
dplyr::group_by(swift_id) |>
dplyr::mutate(visit_id = dplyr::row_number() - 1) |>
dplyr::ungroup() |>
dplyr::left_join(site_codes) |>
dplyr::left_join(station_codes) |>
dplyr::mutate(station_code = tidyr::replace_na(station_code, 'AV999')) |>
dplyr::select(deploy_or_retrieval:deployer_org, site_name, site_code, visit_id, cell_id, mamu_station_id, station_code, swift_id:comments)
}
deployment_df <-
MAMUbioacoustics::read_epicollect(
project_slug = 'mamu-arus',
token = '1fc5154632994f179f7d8b17214e26cb'
)
sd_card_path <- 'E:/'
# wav count
n_wavs <- length(fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav'))
# recording dates
min_date <-
fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav') |>
stringr::str_extract('[0-9]{8}') |>
lubridate::ymd() |>
min()
max_date <-
fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav') |>
stringr::str_extract('[0-9]{8}') |>
lubridate::ymd() |>
max()
# deployment_name
swift <-
fs::dir_ls(sd_card_path) |>
stringr::str_subset('S[0-9]{4}') |>
head(1) |>
stringr::str_extract('S[0-9]{4}')
site <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::distinct(site_code) |>
dplyr::pull(site_code)
load_all()
deployment_df <-
read_epicollect(
project_slug = 'mamu-arus',
token = '1fc5154632994f179f7d8b17214e26cb'
)
sd_card_path <- 'E:/'
# wav count
n_wavs <- length(fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav'))
# recording dates
min_date <-
fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav') |>
stringr::str_extract('[0-9]{8}') |>
lubridate::ymd() |>
min()
max_date <-
fs::dir_ls(sd_card_path, recurse = TRUE, glob = '*.wav') |>
stringr::str_extract('[0-9]{8}') |>
lubridate::ymd() |>
max()
# deployment_name
swift <-
fs::dir_ls(sd_card_path) |>
stringr::str_subset('S[0-9]{4}') |>
head(1) |>
stringr::str_extract('S[0-9]{4}')
site <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::distinct(site_code) |>
dplyr::pull(site_code)
site
cell <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::distinct(cell_id) |>
dplyr::pull(cell_id)
cell
station <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::distinct(station_code) |>
dplyr::pull(station_code)
station
visit <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::filter(visit_id == max(visit_id)) |>
dplyr::pull(visit_id) %>%
stringr::str_c('V', .)
library(tidyverse)
visit <-
deployment_df |>
dplyr::filter(swift_id == swift) |>
dplyr::filter(visit_id == max(visit_id)) |>
dplyr::pull(visit_id) %>%
stringr::str_c('V', .)
visit
tibble::tibble(
n_wavs = n_wavs,
min_date = format(min_date, "%B %d"),
max_date = format(max_date, "%B %d"),
swift_id = swift,
site_id = site_code,
station_id = station_code
visit_id = visit
tibble::tibble(
n_wavs = n_wavs,
min_date = format(min_date, "%B %d"),
max_date = format(max_date, "%B %d"),
swift_id = swift,
site_id = site,
station_id = station,
visit_id = visit
)
library(devtools)
check()
library(readxl)
import(readxl)
library(devtools)
use_package('readxl')
check()
use_package('here')
check()
use_package('tidyr')
check()
use_package('usethis')
check()
use_pipe()
check()
read_epicollect
check()
check()
check()
check()
check()
check()
check()
use_r('set_epicollect_credentials')
check()
use_package('keyring')
check()
check()
library(tidyverse)
library(fs)
dir_ls('F:/')
dir_ls('F:/', recurse = TRUE, glob = '*.wav')
wavs <-
dir_ls('F:/', recurse = TRUE, glob = '*.wav')
wavs
basename(wavs)
library(stringr)
str_replace(wavs, '.', '(-8000).')
wavs
str_replace(wavs, '\\.', '(-8000).')
wavs <-
dir_ls('F:/', recurse = TRUE, glob = '*.wav')
str_replace(wavs, '\\.', '(-0800).')
wavs <-
dir_ls('F:/', recurse = TRUE, glob = '*.wav')
new_wavs <- str_replace(wavs, '\\.', '(-0800).')
fs::file_move(
wavs,
new_wavs
)
path <- "F:/S1732_001/S1732_2023-06-19/S1732_20230619_230002(-0800).wav"
# Remove the time offset in parentheses before ".wav"
clean_path <- str_replace(path, "\\(-?\\d+\\)(?=\\.wav$)", "")
print(clean_path)
